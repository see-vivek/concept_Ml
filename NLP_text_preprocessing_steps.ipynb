{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1oquHr3Tq53fe2BB6BqcA9OdAUfSZTl1-",
      "authorship_tag": "ABX9TyPKSqFyZCYGXHztHLFQndCM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/see-vivek/concept_Ml/blob/main/NLP_text_preprocessing_steps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "IdpvHkLAYbvw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbatb4fyYetM",
        "outputId": "73028224-9234-4fa4-a09a-724586d6a948"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv('/content/drive/MyDrive/only dataset/netflix moview review.csv')"
      ],
      "metadata": {
        "id": "n7x6KDjnZFK0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "X9p8YXcgZPAD",
        "outputId": "6fa7d9cb-8305-4f7f-b3b3-3790230d43ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                                               Text  Target\n",
              "0               0  b'Bromwell High is a cartoon comedy. It ran at...       1\n",
              "1               1  b'Homelessness (or Houselessness as George Car...       1\n",
              "2               2  b'Brilliant over-acting by Lesley Ann Warren. ...       1\n",
              "3               3  b'This is easily the most underrated film inn ...       1\n",
              "4               4  b'This is not the typical Mel Brooks film. It ...       1\n",
              "...           ...                                                ...     ...\n",
              "24995       24995  b\"Towards the end of the movie, I felt it was ...       0\n",
              "24996       24996  b'This is the kind of movie that my enemies co...       0\n",
              "24997       24997  b\"I saw 'Descent' last night at the Stockholm ...       0\n",
              "24998       24998  b\"Some films that you pick up for a pound turn...       0\n",
              "24999       24999  b\"This is one of the dumbest films, I've ever ...       0\n",
              "\n",
              "[25000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0f53a70-3795-4125-aaa3-91d6ac260074\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>b'Bromwell High is a cartoon comedy. It ran at...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>b'Homelessness (or Houselessness as George Car...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>b'Brilliant over-acting by Lesley Ann Warren. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b'This is easily the most underrated film inn ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>b'This is not the typical Mel Brooks film. It ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>24995</td>\n",
              "      <td>b\"Towards the end of the movie, I felt it was ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>24996</td>\n",
              "      <td>b'This is the kind of movie that my enemies co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>24997</td>\n",
              "      <td>b\"I saw 'Descent' last night at the Stockholm ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>24998</td>\n",
              "      <td>b\"Some films that you pick up for a pound turn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>24999</td>\n",
              "      <td>b\"This is one of the dumbest films, I've ever ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0f53a70-3795-4125-aaa3-91d6ac260074')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e0f53a70-3795-4125-aaa3-91d6ac260074 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e0f53a70-3795-4125-aaa3-91d6ac260074');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3dea376a-c818-43a7-9326-47e6a93490f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3dea376a-c818-43a7-9326-47e6a93490f6')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3dea376a-c818-43a7-9326-47e6a93490f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text'][3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "UKb3Tm66ZSp9",
        "outputId": "3cd3aba9-aa7a-4584-c3d8-b9050779d565"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"b'This is easily the most underrated film inn the Brooks cannon. Sure, its flawed. It does not give a realistic view of homelessness (unlike, say, how Citizen Kane gave a realistic view of lounge singers, or Titanic gave a realistic view of Italians YOU IDIOTS). Many of the jokes fall flat. But still, this film is very lovable in a way many comedies are not, and to pull that off in a story about some of the most traditionally reviled members of society is truly impressive. Its not The Fisher King, but its not crap, either. My only complaint is that Brooks should have cast someone else in the lead (I love Mel as a Director and Writer, not so much as a lead).'\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text']=df['Text'].str.lower()##--lower casing of the characters"
      ],
      "metadata": {
        "id": "CGKEjmdFZmXT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text'][5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "QS7vBan7ZuL-",
        "outputId": "c191dbe2-bb76-4bc2-ec9d-fd296ba9fad7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'b\"this isn\\'t the comedic robin williams, nor is it the quirky/insane robin williams of recent thriller fame. this is a hybrid of the classic drama without over-dramatization, mixed with robin\\'s new love of the thriller. but this isn\\'t a thriller, per se. this is more a mystery/suspense vehicle through which williams attempts to locate a sick boy and his keeper.<br /><br />also starring sandra oh and rory culkin, this suspense drama plays pretty much like a news report, until william\\'s character gets close to achieving his goal.<br /><br />i must say that i was highly entertained, though this movie fails to teach, guide, inspect, or amuse. it felt more like i was watching a guy (williams), as he was actually performing the actions, from a third person perspective. in other words, it felt real, and i was able to subscribe to the premise of the story.<br /><br />all in all, it\\'s worth a watch, though it\\'s definitely not friday/saturday night fare.<br /><br />it rates a 7.7/10 from...<br /><br />the fiend :.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'b\"this isn\\'t the comedic robin williams, nor is it the quirky/insane robin williams of recent thriller fame. this is a hybrid of the classic drama without over-dramatization, mixed with robin\\'s new love of the thriller. but this isn\\'t a thriller, per se. this is more a mystery/suspense vehicle through which williams attempts to locate a sick boy and his keeper.<br /><br />also starring sandra oh and rory culkin, this suspense drama plays pretty much like a news report, until william\\'s character gets close to achieving his goal.<br /><br />i must say that i was highly entertained, though this movie fails to teach, guide, inspect, or amuse. it felt more like i was watching a guy (williams), as he was actually performing the actions, from a third person perspective. in other words, it felt real, and i was able to subscribe to the premise of the story.<br /><br />all in all, it\\'s worth a watch, though it\\'s definitely not friday/saturday night fare.<br /><br />it rates a 7.7/10 from'"
      ],
      "metadata": {
        "id": "LyqevGJJcNbV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##now we will remove html tags using python regular expression, regex.\n",
        "#you can use a tool called as regex101.\n",
        "\n",
        "import re\n",
        "def remove_html_tags(text):\n",
        "  pattern= re.compile('<.*?>')\n",
        "  return pattern.sub(r'',text)\n"
      ],
      "metadata": {
        "id": "3fH5-FutaBri"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_html_tags(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "WVYBSCFpb2DZ",
        "outputId": "026e443b-a71c-4919-fc36-024b290019b1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'b\"this isn\\'t the comedic robin williams, nor is it the quirky/insane robin williams of recent thriller fame. this is a hybrid of the classic drama without over-dramatization, mixed with robin\\'s new love of the thriller. but this isn\\'t a thriller, per se. this is more a mystery/suspense vehicle through which williams attempts to locate a sick boy and his keeper.also starring sandra oh and rory culkin, this suspense drama plays pretty much like a news report, until william\\'s character gets close to achieving his goal.i must say that i was highly entertained, though this movie fails to teach, guide, inspect, or amuse. it felt more like i was watching a guy (williams), as he was actually performing the actions, from a third person perspective. in other words, it felt real, and i was able to subscribe to the premise of the story.all in all, it\\'s worth a watch, though it\\'s definitely not friday/saturday night fare.it rates a 7.7/10 from'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text']=df['Text'].apply(remove_html_tags)##- html tag removal from our column names."
      ],
      "metadata": {
        "id": "tFfDFPondFOs"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text'][5]##--- no tag observed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "8kVoiY9Ndo6C",
        "outputId": "2fa01e4f-a6b9-4cce-e14f-230debb2db31"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'b\"this isn\\'t the comedic robin williams, nor is it the quirky/insane robin williams of recent thriller fame. this is a hybrid of the classic drama without over-dramatization, mixed with robin\\'s new love of the thriller. but this isn\\'t a thriller, per se. this is more a mystery/suspense vehicle through which williams attempts to locate a sick boy and his keeper.also starring sandra oh and rory culkin, this suspense drama plays pretty much like a news report, until william\\'s character gets close to achieving his goal.i must say that i was highly entertained, though this movie fails to teach, guide, inspect, or amuse. it felt more like i was watching a guy (williams), as he was actually performing the actions, from a third person perspective. in other words, it felt real, and i was able to subscribe to the premise of the story.all in all, it\\'s worth a watch, though it\\'s definitely not friday/saturday night fare.it rates a 7.7/10 from...the fiend :.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###removal of urls from text. code is below.\n",
        "def remove_url(text):\n",
        "  pattern= re.compile(r'https?://\\S+|WWW\\.\\S+')\n",
        "  return pattern.sub(r'',text)\n"
      ],
      "metadata": {
        "id": "MnRA9rqFd3fg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_url(##--name of variables)"
      ],
      "metadata": {
        "id": "0bLIZc7Ce5S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##remove punchutation marks it is important as we have to tokenise now, during tokenisation they will be treated as word as a result\n",
        "#it will cause heavy dataset, also may be possible during tokenization word and puncutation may act as one word so when word without puncutation may come\n",
        "#you m/c may not understand\n",
        "##syntax for puncutation removal\n",
        "import string\n",
        "exclude= string.punctuation\n",
        "##these all are considered as punctuation in python"
      ],
      "metadata": {
        "id": "BAhJAkcIfExq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_pun(text):\n",
        "  return text.translate(str.maketrans('','',exclude))\n"
      ],
      "metadata": {
        "id": "sOtVvfHmgPvs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text= 'string.with.punctuation?'"
      ],
      "metadata": {
        "id": "wzh1-b8w0_FQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_pun(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KTMw4Fbp29x3",
        "outputId": "b629a36e-98ac-4b19-c7ca-29ee87afde01"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stringwithpunctuation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###chat word treatment.\n",
        "###find chat word dictonary from google. here not present.\n",
        "def chat_conv(text):\n",
        "  new_text=[]\n",
        "  for w in text.split():\n",
        "    if w.upper() in chat_words:\n",
        "      new_text.append(chat_words[w.upper()])\n",
        "    else:\n",
        "        new_text.append(w)\n",
        "\n",
        "  return \" \".join(new_text)\n"
      ],
      "metadata": {
        "id": "HMtGfX994MNQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_conv('gn sleep well')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "LAOPQ4YZ6PTK",
        "outputId": "152a9bbc-8fc5-4823-b7c6-58cd28647998"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-50a2d4359e61>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchat_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gn sleep well'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-91d688661a45>\u001b[0m in \u001b[0;36mchat_conv\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mnew_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchat_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mnew_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'chat_words' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###spelling checking using various library here text blob library is used.\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "OrpOhQqm7OYq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_text= 'some speellings are incorrect we will coreect the spaling of this sentance'"
      ],
      "metadata": {
        "id": "kTz6qX-C7iu-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb = TextBlob(incorrect_text)\n",
        "tb.correct().string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wt7b9saS7xNw",
        "outputId": "7f73b907-4c08-49b0-8875-91cf3aad9a53"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'some swellings are incorrect we will correct the sealing of this sentence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###stop words removal using nltk.\n",
        "!pip install nltk\n",
        "from nltk.corpus import stopwords\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5GO3Q218Uww",
        "outputId": "e76c3f9e-30e2-4ff7-8d9d-cc5a1be3f174"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NupOZ_9KFthC",
        "outputId": "4ccbd672-e418-4f76-9084-b9930017d222"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-KavKjx9MRg",
        "outputId": "e03ab084-0686-4d8a-9ef1-c55bc84013a1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stop_word(text):\n",
        "  new_text=[]\n",
        "   for word in text.split():\n",
        "    if word in stopwords.words('english'):\n",
        "      new_text.append('')\n",
        "\n",
        "      x = new_text[:]\n",
        "      new_text.clear()\n",
        "      return ' '.join(re.X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "xquzWqIT99on",
        "outputId": "ec19eedb-5a65-46d8-a97a-04c505e39ea2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-60-a1188307eb6b>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for word in text.split():\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_stop_word('###pass the statment')"
      ],
      "metadata": {
        "id": "TTAfg25J-ywh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###for removing from whole column use\n",
        "df['column_name'].apply(remove_stop_words)"
      ],
      "metadata": {
        "id": "jt0ltLl4_E_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##removing the emojis--\n",
        "#we will either remove it (removed by using regex)or replace the emoji with meaning(done by below code)\n",
        "import emoji\n",
        "print(emoji.demojize('python is #(suppose that fire emoji is there )'))\n",
        "##it will give output as python is fire.\n"
      ],
      "metadata": {
        "id": "e1TKA8WO_7So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx7vgK4cFh4Q",
        "outputId": "37aeee92-1b72-4080-e01a-00fa3465cd03"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.inputtransformer2 import tokenize\n",
        "###tokenization--process of converting a text into word or sentance or phrase, mostly in words its done.\n",
        "##bets to use nltk.\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n"
      ],
      "metadata": {
        "id": "aTkRsdAqBoiM"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = 'i am going to delhi!'\n",
        "word_tokenize(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O43Lt6t9FCB-",
        "outputId": "b6a28420-daba-4c8d-8aa7-1980d6431ecd"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', 'going', 'to', 'delhi', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent2 = '!!!@@##$$%% come fly with me**&%$#@'\n",
        "word_tokenize(sent2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_TCcEHPF0Lf",
        "outputId": "0f2a85c5-968a-4856-cd58-a25f64d8d592"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!',\n",
              " '!',\n",
              " '!',\n",
              " '@',\n",
              " '@',\n",
              " '#',\n",
              " '#',\n",
              " '$',\n",
              " '$',\n",
              " '%',\n",
              " '%',\n",
              " 'come',\n",
              " 'fly',\n",
              " 'with',\n",
              " 'me',\n",
              " '*',\n",
              " '*',\n",
              " '&',\n",
              " '%',\n",
              " '$',\n",
              " '#',\n",
              " '@']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###spacy best library for tokenization\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "1n_5ZlLHGrU6"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##important step convert the sentances into document.\n",
        "doc1= nlp(sent)\n",
        "doc2= nlp(sent2)"
      ],
      "metadata": {
        "id": "b7YetGTAHd_3"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc1:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T02DJ6rHuaV",
        "outputId": "6a235210-d486-4e3a-fe46-f27838ada8da"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i\n",
            "am\n",
            "going\n",
            "to\n",
            "delhi\n",
            "!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc2:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4CwvupNH-Ld",
        "outputId": "2963e400-4731-4c7a-86dc-556449a1907d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\n",
            "!\n",
            "!\n",
            "@@##$$%%\n",
            "come\n",
            "fly\n",
            "with\n",
            "me**&%$#@\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##steming done by stemmer algos, we will user porter stemmer.\n",
        "from nltk.stem.porter import PorterStemmer\n"
      ],
      "metadata": {
        "id": "RNluIyCGJ4MB"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps= PorterStemmer()\n",
        "def stem_word(text):\n",
        "  return ' '.join([ps.stem(word) for word in text.split()])"
      ],
      "metadata": {
        "id": "HRpia1jtKLO5"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample='walk walking walked walks'\n",
        "stem_word(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BrtlA5yEKkuX",
        "outputId": "1bc366ff-d257-4084-8c31-eeea0700681a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'walk walk walk walk'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text= 'play plays played playing '\n",
        "stem_word(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UScNRdrlK7wV",
        "outputId": "9dd05673-6566-45d6-86a4-75eb557756c0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'play play play play'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##lammatization---here we search in a laxical dictonary\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "word_net_lemmatizer= WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "9oFWqDHIMb16"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7b9fNosPmtW",
        "outputId": "eb749a10-b392-4d19-a9a1-3c2db3167cf7"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentance = 'He was running and eating at tehb same time. He has bad habit of swimming for long hours after playing under sun'"
      ],
      "metadata": {
        "id": "hCH5nrhqM3TP"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "from IPython.core.inputtransformer2 import tokenize\n",
        "sentance_words = nltk.word_tokenize(sentance)\n",
        "punctuation='?:!@#$%.><'\n",
        "for word in sentance_words:\n",
        "  if word in punctuation:\n",
        "    sentance_words.remove(word)\n",
        "\n",
        "sentance_words\n",
        "print(\"{0:20}{1:20}\".format('words','lema'))\n",
        "for word in sentance_words:\n",
        "  print(\"{0:20}{1:20}\".format(word,word_net_lemmatizer.lemmatize(word,pos='v')))#-pos=v means we want verb\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvEid7zZNNYb",
        "outputId": "eae21c2e-2e28-4062-a86f-e534eb030607"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words               lema                \n",
            "He                  He                  \n",
            "was                 be                  \n",
            "running             run                 \n",
            "and                 and                 \n",
            "eating              eat                 \n",
            "at                  at                  \n",
            "tehb                tehb                \n",
            "same                same                \n",
            "time                time                \n",
            "He                  He                  \n",
            "has                 have                \n",
            "bad                 bad                 \n",
            "habit               habit               \n",
            "of                  of                  \n",
            "swimming            swim                \n",
            "for                 for                 \n",
            "long                long                \n",
            "hours               hours               \n",
            "after               after               \n",
            "playing             play                \n",
            "under               under               \n",
            "sun                 sun                 \n"
          ]
        }
      ]
    }
  ]
}